# Machine-learning
## 第1章 绪论
### 1.1 引言
- 根据训练数据是否有标记可将训练任务分为"**有监督学习"**（_supervised learning_）和“**无监督学习**”（_unsupervised learning_），前者有回归和分类，后者有聚类。
- **泛化能力**：模型适用于新样本的能力
- 机器学习在学习过程中对某种类型假设的偏好，称为**归纳偏好**（_inductive bias_）
  任何有效的机器学习算法都必须有归纳偏好，否则就会在看似“等效”的假设空间中的假设所迷惑。比如在同一个训练集我们得出两条拟合曲线，机器学习一定会因为某种原因更加偏好其中一种。那么到底选哪种呢？一般引用的原则是**奥卡姆剃刀**（Occam's razor），即“主张选择与经验观察一致的最简单假设”；当然还有**多解释原则**，”主张保留与经验观察一致的所有假设“，主要应用在集成学习中
- **没有免费午餐定理**（_No Free Lunch Theorem_）：
  1）对所有可能的的目标函数求平均，得到的所有学习算法的“非训练集误差”的期望值相同；
2）对任意固定的训练集，对所有的目标函数求平均，得到的所有学习算法的“非训练集误差”的期望值也相同；
3）对所有的先验知识求平均，得到的所有学习算法的“非训练集误差”的期望值也相同；
4）对任意固定的训练集，对所有的先验知识求平均，得到的所有学习算法的的“非训练集误差”的期望值也相同。
NFL定理表明没有一个学习算法可以在任何领域总是产生最准确的学习器。不管采用何种学习算法，至少存在一个目标函数，能够使得随机猜测算法是更好的算法。这只是理论上，假设了目标函数是均匀分布的，而实际中所有的问题出现的机会和重要性并不相同。
- 数据挖掘与机器学习的联系
数据挖掘受数据库、机器学习、统计学的影响最为深远，数据库为数据挖掘提供了数据管理技术，机器学习和统计学则提供了数据分析的技术，统计学的研究成果通常通过机器学习来形成算法，再进入数据挖掘领域，可以理解成统计学通过机器学习来发挥作用，机器学习和数据库是数据挖掘的两大支撑。（本学期开设了数据挖掘的课程，这里的解释让我茅塞顿开！）

    本章介绍了机器学习的发展历史、重要的基本思想如归纳偏好，以及很有趣的应用场景，最记忆深刻的例子是奥巴马竞选总统时作为”核武器“的半监督学习专家团队，这是一个生动的应用场景，当算法足够强大，能带来的效果是不可估量的。本章最后推荐了机器学习的重要期刊和杂志，对我这个信息搜索的小白很受用，比如

1） 国际学术期刊_Journal of Machine Learning Research_、_Machine Learning_ 

2）人工智能重要会议：_IJCAI、AAAI_以及期刊_Artificial Intelligence、Journal of Artificial Intelligence Research_

3）数据挖掘领域重要会议：_KDD、ICDM_以及期刊_ACM Transaction on Knowledge Discovery from Data、Data Mining and Knowledge Discovery_ 

4）计算机视觉 模式识别领域的重要会议： _CVPR_ 以及重要期刊如 _IEEE ansactions on Pattern  Analysis and Machine Intelligence_

5）神经网络领域的重要期刊如 _Neural Computation IEEE ansactions on Neural Networks and Learning Systems_

6）统计学领域的重要期刊如 _Annals of  Statistics_ 等也常有关于统计学习方面的理论文发表

## 第2章 模型评估与选择
### 2.1 经验误差与过拟合
   误差是评判模型好坏的一个重要指标，指实际预测输出与真实值之间的差距，训练集上的误差称为**训练误差**，新样本上的误差称为**泛化误差**。
   之前在"The Element of Statistics"一书中就已经通过图形理解过拟合，但这里从另一个角度解释了**过拟合**：将训练样本自身的性质当作所有所有潜在样本会具有的一般性质。
  
### 2.2 评估方法
   使用测试集来检验模型对新样本判断的好坏，用测试误差作为泛化误差的近似。如何产生测试集和训练集呢？有以下方法
#### 2.2.1 留出法
   留出法将数据集_D_划分为两个互斥的子集，一个当作训练集_S_另一个为测试集_T_，在_S_上训练后用_T_的误差来估计泛化误差。需注意：划分数据时需采用类似分层抽样的方式以确保样本的类别比例相似；并且单次留出法的结果不可靠，这时采用若干次随机取样、重复多次实验取均值的方式作为最终评估结果。
